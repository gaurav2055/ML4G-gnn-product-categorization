{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40e33c9",
   "metadata": {},
   "source": [
    "# Comprehensive Cold-Start Analysis: All Models\n",
    "## ML4G Course Project - Applications Research with GNNs\n",
    "\n",
    "**Team:** Abhishek Indupally, Pranav Bhimrao Kapadne, Gaurav Suvarna\n",
    "\n",
    "**Goal:** Compare MLP vs GCN vs GraphSAGE vs GraphSAINT on nodes stratified by connectivity\n",
    "\n",
    "**Key Questions:**\n",
    "1. Do GNNs outperform MLP when nodes have 0 edges (true cold-start)?\n",
    "2. At what connectivity threshold do GNNs become worthwhile?\n",
    "3. Which GNN architecture is most resilient to sparse edges?\n",
    "\n",
    "**Degree Stratification:**\n",
    "- Degree 0: Isolated nodes (true cold-start)\n",
    "- Degree 1-5: Sparse connections \n",
    "- Degree 6-20: Moderate connections\n",
    "- Degree 20+: Well-connected nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811b1a7",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961ba60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n",
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "Created directories: images/cold_start/, results/cold_start/\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.serialization import add_safe_globals\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n",
    "from torch_geometric.data.storage import GlobalStorage, NodeStorage, EdgeStorage\n",
    "from torch_geometric.nn import SAGEConv, GCNConv\n",
    "from torch_geometric.utils import degree, subgraph\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Allowlist required torch_geometric classes for safe unpickling\n",
    "add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage, NodeStorage, EdgeStorage, Data, Batch])\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('images/cold_start', exist_ok=True)\n",
    "os.makedirs('results/cold_start', exist_ok=True)\n",
    "print(\"Created directories: images/cold_start/, results/cold_start/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429463db",
   "metadata": {},
   "source": [
    "## 2. Load All Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd37440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING ALL BASELINE RESULTS\n",
      "============================================================\n",
      "MLP baseline: 0.6192\n",
      "GCN baseline: 0.7668\n",
      "GraphSAGE baseline: 0.7609\n",
      "GraphSAINT-RW baseline: 0.7715\n",
      "GraphSAINT-Node baseline: 0.7641\n",
      "\n",
      "Loaded 5 model results for comparison\n",
      "Available models: ['MLP', 'GCN', 'GraphSAGE', 'GraphSAINT-RW', 'GraphSAINT-Node']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING ALL BASELINE RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Store all available results\n",
    "baseline_results = {}\n",
    "\n",
    "# Load MLP results\n",
    "try:\n",
    "    with open('mlp_500k_results.json', 'r') as f:\n",
    "        mlp_results = json.load(f)\n",
    "    baseline_results['MLP'] = mlp_results\n",
    "    print(f\"MLP baseline: {mlp_results['test_accuracy']:.4f}\")\n",
    "except:\n",
    "    print(\"WARNING: mlp_500k_results.json not found\")\n",
    "\n",
    "# Load GCN results  \n",
    "try:\n",
    "    with open('gcn_results.json', 'r') as f:\n",
    "        gcn_results = json.load(f)\n",
    "    baseline_results['GCN'] = gcn_results\n",
    "    print(f\"GCN baseline: {gcn_results['test_accuracy']:.4f}\")\n",
    "except:\n",
    "    print(\"WARNING: gcn_results.json not found\")\n",
    "\n",
    "# Load GraphSAGE results\n",
    "try:\n",
    "    with open('GraphSage_results.json', 'r') as f:\n",
    "        graphsage_results = json.load(f)\n",
    "    baseline_results['GraphSAGE'] = graphsage_results\n",
    "    print(f\"GraphSAGE baseline: {graphsage_results['test_accuracy']:.4f}\")\n",
    "except:\n",
    "    print(\"WARNING: GraphSage_results.json not found\")\n",
    "\n",
    "# Load GraphSAINT-RW results\n",
    "try:\n",
    "    with open('graphsaint_random_walk_results.json', 'r') as f:\n",
    "        saint_rw_results = json.load(f)\n",
    "    baseline_results['GraphSAINT-RW'] = saint_rw_results\n",
    "    print(f\"GraphSAINT-RW baseline: {saint_rw_results['test_accuracy']:.4f}\")\n",
    "except:\n",
    "    print(\"WARNING: graphsaint_random_walk_results.json not found\")\n",
    "\n",
    "# Load GraphSAINT-Node results\n",
    "try:\n",
    "    with open('graphsaint_node_results.json', 'r') as f:\n",
    "        saint_node_results = json.load(f)\n",
    "    baseline_results['GraphSAINT-Node'] = saint_node_results\n",
    "    print(f\"GraphSAINT-Node baseline: {saint_node_results['test_accuracy']:.4f}\")\n",
    "except:\n",
    "    print(\"WARNING: graphsaint_node_results.json not found\")\n",
    "\n",
    "if len(baseline_results) < 2:\n",
    "    print(\"\\nERROR: Need at least 2 models for meaningful comparison\")\n",
    "    print(\"Available models:\", list(baseline_results.keys()))\n",
    "else:\n",
    "    print(f\"\\nLoaded {len(baseline_results)} model results for comparison\")\n",
    "    print(\"Available models:\", list(baseline_results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991654b",
   "metadata": {},
   "source": [
    "## 3. Reproduce Dataset Preparation (Same 500K Subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569c5b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING AND PREPARING DATASET\n",
      "============================================================\n",
      "Original dataset: 2,449,029 nodes, 123,718,280 edges\n",
      "After subsampling: 500,000 nodes, 5,190,420 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING AND PREPARING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load dataset\n",
    "dataset = PygNodePropPredDataset(name=\"ogbn-products\", root=\"data\")\n",
    "data = dataset[0]\n",
    "\n",
    "print(f\"Original dataset: {data.x.shape[0]:,} nodes, {data.edge_index.shape[1]:,} edges\")\n",
    "\n",
    "# Subsample to 500K nodes (same as training notebooks)\n",
    "subsample_size = 500000\n",
    "total_nodes = data.x.shape[0]\n",
    "sampled_indices = torch.randperm(total_nodes)[:subsample_size]\n",
    "sampled_indices = sampled_indices.sort()[0]\n",
    "\n",
    "# Create mapping from old indices to new indices\n",
    "subsample_mapping = {}\n",
    "for new_idx, old_idx in enumerate(sampled_indices):\n",
    "    subsample_mapping[old_idx.item()] = new_idx\n",
    "\n",
    "# Extract subgraph\n",
    "from torch_geometric.utils import subgraph as pyg_subgraph\n",
    "subsampled_edge_index, _ = pyg_subgraph(\n",
    "    subset=sampled_indices,\n",
    "    edge_index=data.edge_index,\n",
    "    relabel_nodes=True,\n",
    "    num_nodes=total_nodes\n",
    ")\n",
    "\n",
    "# Update data object\n",
    "data.x = data.x[sampled_indices]\n",
    "data.y = data.y[sampled_indices]\n",
    "data.edge_index = subsampled_edge_index\n",
    "\n",
    "print(f\"After subsampling: {data.x.shape[0]:,} nodes, {subsampled_edge_index.shape[1]:,} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68aa568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load splits and filter to selected labels (same as training)\n",
    "split_dir = \"data/ogbn_products/split/sales_ranking/\"\n",
    "train_df = pd.read_csv(split_dir + \"train.csv.gz\")\n",
    "valid_df = pd.read_csv(split_dir + \"valid.csv.gz\") \n",
    "test_df = pd.read_csv(split_dir + \"test.csv.gz\")\n",
    "\n",
    "original_train = torch.tensor(train_df.iloc[:, 0].values, dtype=torch.long)\n",
    "original_valid = torch.tensor(valid_df.iloc[:, 0].values, dtype=torch.long)\n",
    "original_test = torch.tensor(test_df.iloc[:, 0].values, dtype=torch.long)\n",
    "\n",
    "# Filter splits to subsample\n",
    "train_in_sample = torch.isin(original_train, sampled_indices)\n",
    "valid_in_sample = torch.isin(original_valid, sampled_indices)\n",
    "test_in_sample = torch.isin(original_test, sampled_indices)\n",
    "\n",
    "filtered_train_original = original_train[train_in_sample]\n",
    "filtered_valid_original = original_valid[valid_in_sample]\n",
    "filtered_test_original = original_test[test_in_sample]\n",
    "\n",
    "# Map to new indices\n",
    "split_idx = {\n",
    "    'train': torch.tensor([subsample_mapping[idx.item()] for idx in filtered_train_original]),\n",
    "    'valid': torch.tensor([subsample_mapping[idx.item()] for idx in filtered_valid_original]),\n",
    "    'test': torch.tensor([subsample_mapping[idx.item()] for idx in filtered_test_original])\n",
    "}\n",
    "\n",
    "print(f\"Splits - Train: {len(split_idx['train']):,}, Valid: {len(split_idx['valid']):,}, Test: {len(split_idx['test']):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c77e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to selected 15 labels (same as training)\n",
    "selected_labels = set(range(16)) - {4}\n",
    "label_mask = torch.tensor([label.item() in selected_labels for label in data.y])\n",
    "filtered_node_indices = torch.where(label_mask)[0]\n",
    "\n",
    "# Filter splits to selected labels\n",
    "train_mask = torch.isin(split_idx['train'], filtered_node_indices)\n",
    "valid_mask = torch.isin(split_idx['valid'], filtered_node_indices)\n",
    "test_mask = torch.isin(split_idx['test'], filtered_node_indices)\n",
    "\n",
    "filtered_train_idx = split_idx['train'][train_mask]\n",
    "filtered_valid_idx = split_idx['valid'][valid_mask]\n",
    "filtered_test_idx = split_idx['test'][test_mask]\n",
    "\n",
    "# Extract final features and labels\n",
    "X = data.x[filtered_node_indices]\n",
    "y = data.y[filtered_node_indices].squeeze()\n",
    "\n",
    "# Remap labels to 0 to num_classes-1\n",
    "label_map = {orig: new for new, orig in enumerate(sorted(selected_labels))}\n",
    "y_mapped = torch.tensor([label_map[label.item()] for label in y])\n",
    "\n",
    "# Extract subgraph for filtered nodes\n",
    "remapped_edges, _ = subgraph(\n",
    "    subset=filtered_node_indices,\n",
    "    edge_index=data.edge_index,\n",
    "    relabel_nodes=True,\n",
    "    num_nodes=data.x.shape[0]\n",
    ")\n",
    "\n",
    "# Create index mapping for splits\n",
    "index_mapping = {orig_idx.item(): new_idx for new_idx, orig_idx in enumerate(filtered_node_indices)}\n",
    "\n",
    "train_idx = torch.tensor([index_mapping[idx.item()] for idx in filtered_train_idx])\n",
    "valid_idx = torch.tensor([index_mapping[idx.item()] for idx in filtered_valid_idx])\n",
    "test_idx = torch.tensor([index_mapping[idx.item()] for idx in filtered_test_idx])\n",
    "\n",
    "num_features = X.shape[1]\n",
    "num_classes = len(selected_labels)\n",
    "\n",
    "print(f\"Final dataset: {X.shape[0]:,} nodes, {remapped_edges.shape[1]:,} edges\")\n",
    "print(f\"Features: {num_features}, Classes: {num_classes}\")\n",
    "print(f\"Test set: {len(test_idx):,} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657d2a5",
   "metadata": {},
   "source": [
    "## 4. Analyze Node Degree Distribution with Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080bfb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NODE DEGREE ANALYSIS WITH STRATIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute node degrees\n",
    "node_degrees = degree(remapped_edges[0], num_nodes=X.shape[0])\n",
    "\n",
    "# Define degree strata\n",
    "degree_strata = {\n",
    "    'isolated': (node_degrees == 0),\n",
    "    'sparse': ((node_degrees >= 1) & (node_degrees <= 5)),\n",
    "    'moderate': ((node_degrees >= 6) & (node_degrees <= 20)),\n",
    "    'well_connected': (node_degrees > 20)\n",
    "}\n",
    "\n",
    "print(f\"Degree stratification:\")\n",
    "total_nodes = X.shape[0]\n",
    "for stratum_name, mask in degree_strata.items():\n",
    "    count = mask.sum().item()\n",
    "    percentage = (count / total_nodes) * 100\n",
    "    min_deg = node_degrees[mask].min().item() if count > 0 else 0\n",
    "    max_deg = node_degrees[mask].max().item() if count > 0 else 0\n",
    "    print(f\"  {stratum_name:<15}: {count:>6,} nodes ({percentage:>5.1f}%) [degree {min_deg}-{max_deg}]\")\n",
    "\n",
    "# Overall degree statistics\n",
    "degree_stats = {\n",
    "    'mean': node_degrees.mean().item(),\n",
    "    'median': node_degrees.median().item(),\n",
    "    'min': node_degrees.min().item(),\n",
    "    'max': node_degrees.max().item(),\n",
    "    'std': node_degrees.std().item()\n",
    "}\n",
    "\n",
    "print(f\"\\nOverall degree statistics:\")\n",
    "print(f\"  Mean: {degree_stats['mean']:.2f}\")\n",
    "print(f\"  Median: {degree_stats['median']:.2f}\")\n",
    "print(f\"  Range: {degree_stats['min']:.0f} - {degree_stats['max']:.0f}\")\n",
    "print(f\"  Std: {degree_stats['std']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac45592",
   "metadata": {},
   "source": [
    "## 5. Load All Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING ALL TRAINED MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define model architectures\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lin1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index=None):\n",
    "        # MLP ignores edge_index for consistent API\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Load models\n",
    "hidden_channels = 128\n",
    "models = {}\n",
    "\n",
    "# Model loading configuration\n",
    "model_configs = [\n",
    "    ('MLP', 'models/mlp_best.pt', MLP),\n",
    "    ('GCN', 'models/gcn_best.pt', GCN),\n",
    "    ('GraphSAGE', 'models/graphsage_best.pt', GraphSAGE),\n",
    "    ('GraphSAINT-RW', 'models/graphsaint_rw_best.pt', GraphSAGE),\n",
    "    ('GraphSAINT-Node', 'models/graphsaint_node_best.pt', GraphSAGE)\n",
    "]\n",
    "\n",
    "for model_name, model_path, model_class in model_configs:\n",
    "    if model_name in baseline_results and os.path.exists(model_path):\n",
    "        try:\n",
    "            model = model_class(num_features, hidden_channels, num_classes, dropout=0.5)\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "            models[model_name] = model\n",
    "            print(f\"Loaded {model_name} model\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR loading {model_name}: {e}\")\n",
    "    else:\n",
    "        if model_name not in baseline_results:\n",
    "            print(f\"Skipping {model_name}: no baseline results\")\n",
    "        else:\n",
    "            print(f\"Skipping {model_name}: model file not found\")\n",
    "\n",
    "if len(models) < 2:\n",
    "    print(\"\\nERROR: Need at least 2 models for comparison\")\n",
    "    print(\"Loaded models:\", list(models.keys()))\n",
    "    raise RuntimeError(\"Insufficient models loaded\")\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(models)} models: {list(models.keys())}\")\n",
    "\n",
    "# Move data to device\n",
    "X = X.to(device)\n",
    "y_mapped = y_mapped.to(device)\n",
    "remapped_edges = remapped_edges.to(device)\n",
    "test_idx = test_idx.to(device)\n",
    "node_degrees = node_degrees.to(device)\n",
    "\n",
    "degree_strata = {k: v.to(device) for k, v in degree_strata.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ff781",
   "metadata": {},
   "source": [
    "## 6. Cold-Start Analysis by Degree Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLD-START ANALYSIS BY DEGREE STRATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_stratum(model, x, edge_index, test_mask, y_test, stratum_mask, model_name):\n",
    "    \"\"\"Evaluate model on specific degree stratum.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get test nodes in this stratum\n",
    "    test_in_stratum = test_mask[stratum_mask[test_mask]]\n",
    "    \n",
    "    if len(test_in_stratum) == 0:\n",
    "        return 0.0, 0\n",
    "    \n",
    "    # Forward pass (different for MLP vs GNN)\n",
    "    if isinstance(model, MLP):\n",
    "        out = model(x[test_in_stratum])\n",
    "    else:\n",
    "        # For GNNs, need full graph but evaluate on subset\n",
    "        out = model(x, edge_index)\n",
    "        out = out[test_in_stratum]\n",
    "    \n",
    "    y_true = y_test[test_in_stratum]\n",
    "    pred = out.argmax(dim=1)\n",
    "    accuracy = (pred == y_true).float().mean().item()\n",
    "    \n",
    "    return accuracy, len(test_in_stratum)\n",
    "\n",
    "# Run analysis across all degree strata\n",
    "results_by_stratum = {\n",
    "    'stratum': [],\n",
    "    'degree_range': [],\n",
    "    'num_test_nodes': []\n",
    "}\n",
    "\n",
    "# Add columns for each model\n",
    "for model_name in models.keys():\n",
    "    results_by_stratum[f'{model_name}_accuracy'] = []\n",
    "\n",
    "print(\"Testing performance across degree strata...\")\n",
    "print(f\"{'Stratum':<15} {'Range':<12} {'Test Nodes':<10} \", end='')\n",
    "for model_name in models.keys():\n",
    "    print(f\"{model_name:<12}\", end=' ')\n",
    "print()\n",
    "print(\"-\" * (15 + 12 + 10 + 12 * len(models) + len(models)))\n",
    "\n",
    "for stratum_name, stratum_mask in degree_strata.items():\n",
    "    # Skip if no test nodes in this stratum\n",
    "    test_in_stratum_mask = stratum_mask[test_idx]\n",
    "    num_test_nodes = test_in_stratum_mask.sum().item()\n",
    "    \n",
    "    if num_test_nodes == 0:\n",
    "        print(f\"{stratum_name:<15} {'N/A':<12} {0:<10} No test nodes\")\n",
    "        continue\n",
    "    \n",
    "    # Get degree range for this stratum\n",
    "    stratum_degrees = node_degrees[stratum_mask]\n",
    "    if len(stratum_degrees) > 0:\n",
    "        min_deg = stratum_degrees.min().item()\n",
    "        max_deg = stratum_degrees.max().item()\n",
    "        if min_deg == max_deg:\n",
    "            degree_range = f\"{min_deg}\"\n",
    "        else:\n",
    "            degree_range = f\"{min_deg}-{max_deg}\"\n",
    "    else:\n",
    "        degree_range = \"N/A\"\n",
    "    \n",
    "    # Store basic info\n",
    "    results_by_stratum['stratum'].append(stratum_name)\n",
    "    results_by_stratum['degree_range'].append(degree_range)\n",
    "    results_by_stratum['num_test_nodes'].append(num_test_nodes)\n",
    "    \n",
    "    print(f\"{stratum_name:<15} {degree_range:<12} {num_test_nodes:<10} \", end='')\n",
    "    \n",
    "    # Test each model on this stratum\n",
    "    for model_name, model in models.items():\n",
    "        accuracy, _ = evaluate_on_stratum(\n",
    "            model, X, remapped_edges, test_idx, y_mapped, stratum_mask, model_name\n",
    "        )\n",
    "        results_by_stratum[f'{model_name}_accuracy'].append(accuracy)\n",
    "        print(f\"{accuracy:.4f}    \", end='')\n",
    "    \n",
    "    print()  # New line after each stratum\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results_by_stratum)\n",
    "print(f\"\\nCold-Start Analysis Results by Degree Strata:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc94405",
   "metadata": {},
   "source": [
    "## 7. Isolated Nodes Analysis (Degree = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d176f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED ISOLATED NODES ANALYSIS (DEGREE = 0)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Find isolated nodes (degree = 0)\n",
    "isolated_mask = node_degrees == 0\n",
    "isolated_test_mask = isolated_mask[test_idx]\n",
    "isolated_test_nodes = test_idx[isolated_test_mask]\n",
    "\n",
    "print(f\"Total isolated nodes: {isolated_mask.sum().item():,}\")\n",
    "print(f\"Isolated test nodes: {len(isolated_test_nodes):,}\")\n",
    "\n",
    "if len(isolated_test_nodes) > 0:\n",
    "    print(f\"\\nPerformance on isolated nodes (true cold-start scenario):\")\n",
    "    print(f\"{'Model':<15} {'Accuracy':<10} {'vs Baseline':<12}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    isolated_results = {}\n",
    "    \n",
    "    # Evaluate each model on isolated nodes\n",
    "    for model_name, model in models.items():\n",
    "        with torch.no_grad():\n",
    "            if isinstance(model, MLP):\n",
    "                out = model(X[isolated_test_nodes])\n",
    "            else:\n",
    "                # For GNNs, use full graph but evaluate on isolated nodes\n",
    "                out = model(X, remapped_edges)\n",
    "                out = out[isolated_test_nodes]\n",
    "            \n",
    "            pred = out.argmax(dim=1)\n",
    "            accuracy = (pred == y_mapped[isolated_test_nodes]).float().mean().item()\n",
    "            isolated_results[model_name] = accuracy\n",
    "            \n",
    "            # Compare to baseline result\n",
    "            baseline_acc = baseline_results[model_name]['test_accuracy']\n",
    "            difference = accuracy - baseline_acc\n",
    "            \n",
    "            print(f\"{model_name:<15} {accuracy:.4f}     {difference:+.4f}\")\n",
    "    \n",
    "    # Find best and worst performers on isolated nodes\n",
    "    best_model = max(isolated_results, key=isolated_results.get)\n",
    "    worst_model = min(isolated_results, key=isolated_results.get)\n",
    "    \n",
    "    print(f\"\\nBest on isolated nodes: {best_model} ({isolated_results[best_model]:.4f})\")\n",
    "    print(f\"Worst on isolated nodes: {worst_model} ({isolated_results[worst_model]:.4f})\")\n",
    "    print(f\"Gap: {isolated_results[best_model] - isolated_results[worst_model]:.4f}\")\n",
    "    \n",
    "    # Analyze label distribution of isolated nodes\n",
    "    isolated_labels = y_mapped[isolated_test_nodes]\n",
    "    unique_labels, label_counts = torch.unique(isolated_labels, return_counts=True)\n",
    "    \n",
    "    print(f\"\\nLabel distribution of isolated test nodes:\")\n",
    "    for label, count in zip(unique_labels, label_counts):\n",
    "        percentage = (count.item() / len(isolated_test_nodes)) * 100\n",
    "        print(f\"  Label {label.item()}: {count.item()} nodes ({percentage:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"No isolated nodes in test set\")\n",
    "    isolated_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345cb5e4",
   "metadata": {},
   "source": [
    "## 8. Connectivity Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONNECTIVITY THRESHOLD ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test performance at different degree thresholds\n",
    "degree_thresholds = [0, 1, 2, 3, 5, 10, 20, 50]\n",
    "threshold_results = {\n",
    "    'threshold': [],\n",
    "    'num_test_nodes': []\n",
    "}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    threshold_results[f'{model_name}_accuracy'] = []\n",
    "\n",
    "print(\"Finding connectivity thresholds where GNNs become worthwhile...\")\n",
    "print(f\"\\n{'Degree <=':<10} {'Test Nodes':<12} \", end='')\n",
    "for model_name in models.keys():\n",
    "    print(f\"{model_name:<12}\", end=' ')\n",
    "print()\n",
    "print(\"-\" * (10 + 12 + 12 * len(models) + len(models)))\n",
    "\n",
    "for threshold in degree_thresholds:\n",
    "    # Create mask for nodes with degree <= threshold\n",
    "    threshold_mask = node_degrees <= threshold\n",
    "    test_in_threshold = test_idx[threshold_mask[test_idx]]\n",
    "    num_test_nodes = len(test_in_threshold)\n",
    "    \n",
    "    threshold_results['threshold'].append(threshold)\n",
    "    threshold_results['num_test_nodes'].append(num_test_nodes)\n",
    "    \n",
    "    print(f\"{threshold:<10} {num_test_nodes:<12} \", end='')\n",
    "    \n",
    "    if num_test_nodes == 0:\n",
    "        # No nodes at this threshold\n",
    "        for model_name in models.keys():\n",
    "            threshold_results[f'{model_name}_accuracy'].append(0.0)\n",
    "        print(\"No nodes\")\n",
    "        continue\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model_name, model in models.items():\n",
    "        accuracy, _ = evaluate_on_stratum(\n",
    "            model, X, remapped_edges, test_idx, y_mapped, threshold_mask, model_name\n",
    "        )\n",
    "        threshold_results[f'{model_name}_accuracy'].append(accuracy)\n",
    "        print(f\"{accuracy:.4f}    \", end='')\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Convert to DataFrame\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "# Find crossover points where GNNs beat MLP\n",
    "if 'MLP' in models:\n",
    "    mlp_accs = threshold_df['MLP_accuracy'].values\n",
    "    print(f\"\\nCrossover analysis (where GNNs beat MLP):\")\n",
    "    print(f\"{'Model':<15} {'Crossover Threshold':<20} {'Improvement':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for model_name in models.keys():\n",
    "        if model_name == 'MLP':\n",
    "            continue\n",
    "            \n",
    "        model_accs = threshold_df[f'{model_name}_accuracy'].values\n",
    "        crossover_threshold = None\n",
    "        \n",
    "        for i, (mlp_acc, model_acc) in enumerate(zip(mlp_accs, model_accs)):\n",
    "            if model_acc > mlp_acc and threshold_df['num_test_nodes'].iloc[i] > 50:  # Require sufficient sample size\n",
    "                crossover_threshold = threshold_df['threshold'].iloc[i]\n",
    "                improvement = model_acc - mlp_acc\n",
    "                print(f\"{model_name:<15} degree <= {crossover_threshold:<12} {improvement:+.4f}\")\n",
    "                break\n",
    "        \n",
    "        if crossover_threshold is None:\n",
    "            print(f\"{model_name:<15} {'No crossover':<20} {'N/A':<12}\")\n",
    "\n",
    "print(f\"\\nThreshold Analysis Results:\")\n",
    "print(threshold_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6ece6",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "model_colors = plt.cm.tab10(np.linspace(0, 1, len(models)))\n",
    "color_map = {model: color for model, color in zip(models.keys(), model_colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Performance by Degree Strata\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left plot: Accuracy by stratum\n",
    "strata_names = results_df['stratum'].values\n",
    "x_pos = np.arange(len(strata_names))\n",
    "bar_width = 0.8 / len(models)\n",
    "\n",
    "for i, model_name in enumerate(models.keys()):\n",
    "    accuracies = results_df[f'{model_name}_accuracy'].values\n",
    "    ax1.bar(x_pos + i * bar_width, accuracies, bar_width, \n",
    "           label=model_name, color=color_map[model_name], alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Degree Stratum', fontweight='bold')\n",
    "ax1.set_ylabel('Test Accuracy', fontweight='bold')\n",
    "ax1.set_title('Performance by Node Connectivity Level', fontweight='bold')\n",
    "ax1.set_xticks(x_pos + bar_width * (len(models) - 1) / 2)\n",
    "ax1.set_xticklabels(strata_names, rotation=0)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, max(1, max([results_df[f'{m}_accuracy'].max() for m in models.keys()]) * 1.1))\n",
    "\n",
    "# Right plot: Node count by stratum\n",
    "node_counts = results_df['num_test_nodes'].values\n",
    "ax2.bar(strata_names, node_counts, color='lightblue', alpha=0.7, edgecolor='navy')\n",
    "ax2.set_xlabel('Degree Stratum', fontweight='bold')\n",
    "ax2.set_ylabel('Number of Test Nodes', fontweight='bold')\n",
    "ax2.set_title('Test Node Distribution by Connectivity', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, count in enumerate(node_counts):\n",
    "    ax2.text(i, count + max(node_counts) * 0.01, f'{count:,}', \n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/cold_start/performance_by_strata.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce1eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Connectivity Threshold Analysis\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "thresholds = threshold_df['threshold'].values\n",
    "for model_name in models.keys():\n",
    "    accuracies = threshold_df[f'{model_name}_accuracy'].values\n",
    "    ax.plot(thresholds, accuracies, marker='o', linewidth=2, markersize=8, \n",
    "           label=model_name, color=color_map[model_name])\n",
    "\n",
    "ax.set_xlabel('Maximum Node Degree (Cumulative)', fontweight='bold')\n",
    "ax.set_ylabel('Test Accuracy', fontweight='bold')\n",
    "ax.set_title('Performance vs Connectivity Threshold\\n(Cumulative: nodes with degree <= threshold)', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-1, max(thresholds) + 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/cold_start/threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696723a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: GNN vs MLP Advantage by Connectivity\n",
    "if 'MLP' in models:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    mlp_accs = threshold_df['MLP_accuracy'].values\n",
    "    \n",
    "    for model_name in models.keys():\n",
    "        if model_name == 'MLP':\n",
    "            continue\n",
    "        \n",
    "        model_accs = threshold_df[f'{model_name}_accuracy'].values\n",
    "        advantages = model_accs - mlp_accs\n",
    "        \n",
    "        # Color positive and negative advantages differently\n",
    "        colors = ['green' if x >= 0 else 'red' for x in advantages]\n",
    "        \n",
    "        ax.bar(thresholds + np.arange(len(models.keys()) - 1).tolist().index(list(models.keys()).index(model_name) - 1) * 0.1, \n",
    "               advantages, width=0.8/len(models), alpha=0.7,\n",
    "               label=f'{model_name} - MLP', color=color_map[model_name])\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax.set_xlabel('Maximum Node Degree', fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy Advantage over MLP', fontweight='bold')\n",
    "    ax.set_title('GNN Advantage over MLP by Connectivity Level', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/cold_start/gnn_mlp_advantage.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa6350",
   "metadata": {},
   "source": [
    "## 10. Analysis Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPREHENSIVE COLD-START ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nKEY FINDINGS:\")\n",
    "\n",
    "# 1. Isolated nodes performance\n",
    "if isolated_results:\n",
    "    print(\"\\n1. TRUE COLD-START PERFORMANCE (Degree = 0):\")\n",
    "    for model_name, acc in isolated_results.items():\n",
    "        baseline_acc = baseline_results[model_name]['test_accuracy']\n",
    "        degradation = baseline_acc - acc\n",
    "        print(f\"   {model_name:<15}: {acc:.4f} (degradation: {degradation:.4f})\")\n",
    "    \n",
    "    best_isolated = max(isolated_results, key=isolated_results.get)\n",
    "    worst_isolated = min(isolated_results, key=isolated_results.get)\n",
    "    print(f\"   Best isolated: {best_isolated} ({isolated_results[best_isolated]:.4f})\")\n",
    "    print(f\"   Worst isolated: {worst_isolated} ({isolated_results[worst_isolated]:.4f})\")\n",
    "\n",
    "# 2. Connectivity advantages\n",
    "print(\"\\n2. CONNECTIVITY ADVANTAGES:\")\n",
    "for stratum_name in ['sparse', 'moderate', 'well_connected']:\n",
    "    if stratum_name in results_df['stratum'].values:\n",
    "        idx = results_df[results_df['stratum'] == stratum_name].index[0]\n",
    "        print(f\"   {stratum_name.replace('_', ' ').title()} connections:\")\n",
    "        for model_name in models.keys():\n",
    "            acc = results_df.loc[idx, f'{model_name}_accuracy']\n",
    "            print(f\"     {model_name}: {acc:.4f}\")\n",
    "\n",
    "# 3. Best model by connectivity level\n",
    "print(\"\\n3. BEST MODEL BY CONNECTIVITY LEVEL:\")\n",
    "for i, row in results_df.iterrows():\n",
    "    stratum = row['stratum']\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for model_name in models.keys():\n",
    "        acc = row[f'{model_name}_accuracy']\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model = model_name\n",
    "    print(f\"   {stratum.replace('_', ' ').title():<15}: {best_model} ({best_acc:.4f})\")\n",
    "\n",
    "# 4. When do GNNs become worthwhile?\n",
    "if 'MLP' in models:\n",
    "    print(\"\\n4. GNN WORTHINESS THRESHOLDS:\")\n",
    "    mlp_accs = threshold_df['MLP_accuracy'].values\n",
    "    for model_name in models.keys():\n",
    "        if model_name == 'MLP':\n",
    "            continue\n",
    "        \n",
    "        model_accs = threshold_df[f'{model_name}_accuracy'].values\n",
    "        worthwhile_threshold = None\n",
    "        \n",
    "        for i, (mlp_acc, model_acc) in enumerate(zip(mlp_accs, model_accs)):\n",
    "            if model_acc > mlp_acc and threshold_df['num_test_nodes'].iloc[i] > 50:\n",
    "                worthwhile_threshold = threshold_df['threshold'].iloc[i]\n",
    "                break\n",
    "        \n",
    "        if worthwhile_threshold is not None:\n",
    "            print(f\"   {model_name}: degree > {worthwhile_threshold}\")\n",
    "        else:\n",
    "            print(f\"   {model_name}: never clearly better than MLP\")\n",
    "\n",
    "print(f\"\\n5. BASELINE COMPARISON (All test nodes):\")\n",
    "for model_name in models.keys():\n",
    "    acc = baseline_results[model_name]['test_accuracy']\n",
    "    print(f\"   {model_name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302155e",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26bd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "comprehensive_results = {\n",
    "    'experiment': 'Comprehensive Cold-Start Analysis',\n",
    "    'models_analyzed': list(models.keys()),\n",
    "    'dataset_info': {\n",
    "        'total_nodes': int(X.shape[0]),\n",
    "        'total_edges': int(remapped_edges.shape[1]),\n",
    "        'test_nodes': int(len(test_idx)),\n",
    "        'features': int(num_features),\n",
    "        'classes': int(num_classes)\n",
    "    },\n",
    "    'degree_statistics': degree_stats,\n",
    "    'degree_strata': {\n",
    "        stratum: {\n",
    "            'node_count': int(mask.sum().item()),\n",
    "            'percentage': float((mask.sum().item() / X.shape[0]) * 100)\n",
    "        }\n",
    "        for stratum, mask in degree_strata.items()\n",
    "    },\n",
    "    'performance_by_strata': results_df.to_dict('records'),\n",
    "    'connectivity_threshold_analysis': threshold_df.to_dict('records'),\n",
    "    'isolated_nodes_analysis': isolated_results if isolated_results else {},\n",
    "    'baseline_accuracies': {\n",
    "        model: baseline_results[model]['test_accuracy']\n",
    "        for model in models.keys()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "with open('results/cold_start/comprehensive_cold_start_results.json', 'w') as f:\n",
    "    json.dump(comprehensive_results, f, indent=2)\n",
    "\n",
    "# Save detailed tables\n",
    "results_df.to_csv('results/cold_start/performance_by_strata.csv', index=False)\n",
    "threshold_df.to_csv('results/cold_start/threshold_analysis.csv', index=False)\n",
    "\n",
    "print(\"\\nResults saved:\")\n",
    "print(\"  - results/cold_start/comprehensive_cold_start_results.json\")\n",
    "print(\"  - results/cold_start/performance_by_strata.csv\")\n",
    "print(\"  - results/cold_start/threshold_analysis.csv\")\n",
    "\n",
    "print(\"\\nGenerated visualizations:\")\n",
    "print(\"  - images/cold_start/performance_by_strata.png\")\n",
    "print(\"  - images/cold_start/threshold_analysis.png\") \n",
    "if 'MLP' in models:\n",
    "    print(\"  - images/cold_start/gnn_mlp_advantage.png\")\n",
    "\n",
    "print(f\"\\nCOMPREHENSIVE COLD-START ANALYSIS COMPLETE!\")\n",
    "print(f\"Analyzed {len(models)} models across {len(degree_strata)} connectivity levels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4g",
   "language": "python",
   "name": "ml4g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
